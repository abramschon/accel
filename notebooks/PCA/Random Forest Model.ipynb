{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bac5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn import manifold\n",
    "from sklearn import metrics\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, explained_variance_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3049a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(X, Y, ratio):\n",
    "    \"\"\" Function to split the dataset into train and test \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=ratio)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def score(y_true,y_pred): \n",
    "    \"\"\" Function to print the metrics of interest of the model \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred) #set score here and not below if using MSE in GridCV\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    ev = explained_variance_score(y_true, y_pred)\n",
    "    print(\"MSE is: \", mse)\n",
    "    print(\"R2 is: \", r2)\n",
    "    print(\"Explained variance is:\", ev)\n",
    "    \n",
    "def model_tune(model_name, params, X_train, y_train):\n",
    "    if model_name == 'knn':\n",
    "        model = KNeighborsRegressor(algorithm='auto')\n",
    "    elif model_name == 'rf':\n",
    "        model = RandomForestRegressor()\n",
    "    elif model_name == 'regression':\n",
    "        model = ElasticNet()\n",
    "    else:\n",
    "        print('Model unrecognised')\n",
    "    # Tune the model with Bayesian optimisation\n",
    "    opt = BayesSearchCV(model, param_grid, n_iter=30, cv=5, verbose=1)\n",
    "    opt.fit(X_train, y_train)\n",
    "    # With the following parameter combination being optimal\n",
    "    print(\"Best parameter combo:\", opt.best_params_)\n",
    "    # Having the following score\n",
    "    print(\"Best validation MSE:\", opt.best_score_)\n",
    "    return opt.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f34302",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759517a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "PATH = '/cdtshared/wearables/students/group5/'\n",
    "\n",
    "# Features from biobank\n",
    "X_train = pd.read_pickle(PATH+\"XtrainPCA.pkl\")\n",
    "X_val = pd.read_pickle(PATH+\"XvalPCA.pkl\")\n",
    "X_test = pd.read_pickle(PATH+\"XtestPCA.pkl\")\n",
    "# Outcome\n",
    "y_train = pd.read_pickle(PATH+\"ytrainPCA.pkl\")\n",
    "y_val = pd.read_pickle(PATH+\"yvalPCA.pkl\")\n",
    "y_test = pd.read_pickle(PATH+\"ytestPCA.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9717a",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184002e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters you want to sweep through (important it is manual for generalisation)\n",
    "# C for regularisation if doing regression\n",
    "# kernel if doing SVM for example\n",
    "\n",
    "# In this case we are tuning for RF hyperparameters\n",
    "# Number of trees in random forest\n",
    "n_estimators = [10, 25, 50, 100, 150]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10, 50]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5cdfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0e095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fold corresponding to our own train and validation split\n",
    "X = np.vstack((X_train, X_val))\n",
    "test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_val.shape[0])]\n",
    "y = np.concatenate([y_train, y_val])\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip to bayesian below if taking too long to compute\n",
    "clf = GridSearchCV(model, param_grid, cv=ps, refit=False)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", clf.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best validation MSE:\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test set performance\n",
    "score(y_test, model_best.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f770abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "              estimator=RandomForestRegressor(), n_iter=30, refit=False,\n",
       "              search_spaces={'bootstrap': [True, False],\n",
       "                             'max_depth': [10, 50, None],\n",
       "                             'max_features': ['auto', 'sqrt'],\n",
       "                             'min_samples_leaf': [2, 4, 10],\n",
       "                             'min_samples_split': [5, 10],\n",
       "                             'n_estimators': [10, 25, 50, 100, 150]},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(model, param_grid, n_iter=30, cv=ps, verbose=1, refit=False)\n",
    "opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f9f5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter combo: OrderedDict([('bootstrap', True), ('max_depth', 10), ('max_features', 'sqrt'), ('min_samples_leaf', 10), ('min_samples_split', 5), ('n_estimators', 150)])\n",
      "Best validation MSE: 4.5703579451328524e-02\n"
     ]
    }
   ],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best validation MSE:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d447718",
   "metadata": {},
   "source": [
    "Best parameters: <br>\n",
    "**bootstrap**:True <br>\n",
    "**max_depth**: None <br>\n",
    "**max_features**: 'auto' <br>\n",
    "**min_samples_leaf**: 10 <br>\n",
    "**min_samples_split**: 7 <br>\n",
    "**n_estimators**: 150 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8715abce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=10, min_samples_split=7,\n",
       "                      n_estimators=150)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(bootstrap=True, max_depth=None, max_features='auto', min_samples_leaf = 10, min_samples_split = 7, n_estimators = 150)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53cd555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is:  78.66941627008907\n",
      "R2 is:  0.12852909228073706\n",
      "Explained variance is: 0.1286197497199666\n"
     ]
    }
   ],
   "source": [
    "score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "637bf940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is:  75.79955331865284\n",
      "R2 is:  0.13651836337385337\n",
      "Explained variance is: 0.13655154443210693\n"
     ]
    }
   ],
   "source": [
    "# Get the test set performance\n",
    "score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c6707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
