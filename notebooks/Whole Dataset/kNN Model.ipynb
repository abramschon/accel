{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bac5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn import manifold\n",
    "from sklearn import metrics\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, explained_variance_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3049a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(X, Y, ratio):\n",
    "    \"\"\" Function to split the dataset into train and test \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=ratio)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def score(y_true,y_pred): \n",
    "    \"\"\" Function to print the metrics of interest of the model \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred) #set score here and not below if using MSE in GridCV\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    ev = explained_variance_score(y_true, y_pred)\n",
    "    print(\"MSE is: \", mse)\n",
    "    print(\"R2 is: \", r2)\n",
    "    print(\"Explained variance is:\", ev)\n",
    "    \n",
    "def model_tune(model_name, params, X_train, y_train):\n",
    "    if model_name == 'knn':\n",
    "        model = KNeighborsRegressor(algorithm='auto')\n",
    "    elif model_name == 'rf':\n",
    "        model = RandomForestRegressor()\n",
    "    elif model_name == 'regression':\n",
    "        model = ElasticNet()\n",
    "    else:\n",
    "        print('Model unrecognised')\n",
    "    # Tune the model with Bayesian optimisation\n",
    "    opt = BayesSearchCV(model, param_grid, n_iter=30, cv=5, verbose=1)\n",
    "    opt.fit(X_train, y_train)\n",
    "    # With the following parameter combination being optimal\n",
    "    print(\"Best parameter combo:\", opt.best_params_)\n",
    "    # Having the following score\n",
    "    print(\"Best validation MSE:\", opt.best_score_)\n",
    "    return opt.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f34302",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759517a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "PATH = '/cdtshared/wearables/students/group5/'\n",
    "\n",
    "# Features from biobank\n",
    "features = pd.read_pickle(PATH+\"imputed_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f91696",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_of_interest = list(set(list(features.columns)) - set(['acc.overall.avg']))\n",
    "\n",
    "Y = features['acc.overall.avg']\n",
    "X = features[features_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73031a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the categorical features\n",
    "categorical_features = []\n",
    "for columns in list(X.columns):\n",
    "    if features[columns].dtype=='object':\n",
    "        categorical_features.append(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc1176",
   "metadata": {},
   "source": [
    "# Data preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020973b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variables\n",
    "X_enc = pd.get_dummies(X, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d06a6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d27a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (69589, 1139)\n",
      "Shape of validation set: (19882, 1139)\n",
      "Shape of test set: (9942, 1139)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing, 70:20:10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, Y, test_size=0.3)\n",
    "\n",
    "# Split into training and validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.1/(0.1 + 0.2))\n",
    "\n",
    "print(\"Shape of training set:\", X_train.shape)\n",
    "print(\"Shape of validation set:\", X_val.shape)\n",
    "print(\"Shape of test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9717a",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "184002e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters you want to sweep through (important it is manual for generalisation)\n",
    "# C for regularisation if doing regression\n",
    "# kernel if doing SVM for example\n",
    "\n",
    "# In this case we are tuning for kNN hyperparameters\n",
    "# Number of neighbours in kNN\n",
    "n_neighbors = [3, 5, 7, 10]\n",
    "# Leaf size passed to BallTree or KDTree\n",
    "leaf_size = [1, 20, 30, 40]\n",
    "# Whether using Minkowski or Euclidean distance\n",
    "p = [1, 2]\n",
    "# How to weigh the distance proximity\n",
    "weights = ['uniform', 'distance']\n",
    "# The distance metric to use for the tree.\n",
    "metric = ['minkowski', 'chebyshev']\n",
    "\n",
    "# Create the grid\n",
    "param_grid = {'n_neighbors': n_neighbors,\n",
    "               'leaf_size': leaf_size,\n",
    "               'p': p,\n",
    "               'weights': weights,\n",
    "               'metric': metric}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cdfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "model = KNeighborsRegressor(algorithm='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0e095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fold corresponding to our own train and validation split\n",
    "X = np.vstack((X_train, X_val))\n",
    "test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_val.shape[0])]\n",
    "y = np.concatenate([y_train, y_val])\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip to bayesian below if taking too long to compute\n",
    "clf = GridSearchCV(model, param_grid, cv=ps, refit=False)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", clf.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best validation MSE:\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test set performance\n",
    "score(y_test, model_best.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f770abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "              estimator=KNeighborsRegressor(), n_iter=30, refit=False,\n",
       "              search_spaces={'leaf_size': [1, 20, 30, 40],\n",
       "                             'metric': ['minkowski', 'chebyshev'],\n",
       "                             'n_neighbors': [3, 5, 7, 10], 'p': [1, 2],\n",
       "                             'weights': ['uniform', 'distance']},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(model, param_grid, n_iter=30, cv=ps, verbose=1, refit=False)\n",
    "opt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9f5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter combo: OrderedDict([('leaf_size', 1), ('metric', 'minkowski'), ('n_neighbors', 10), ('p', 2), ('weights', 'distance')])\n",
      "Best validation MSE: -6.225981106621581e-02\n"
     ]
    }
   ],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best validation MSE:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d447718",
   "metadata": {},
   "source": [
    "Best parameters: <br>\n",
    "**leaf_size**:1 <br>\n",
    "**metric**: minkowski <br>\n",
    "**n_neighbors**: 10 <br>\n",
    "**p**: 2 <br>\n",
    "**weights**: distance <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8715abce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(leaf_size=1, n_neighbors=10, weights='distance')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsRegressor(algorithm='auto', leaf_size=1, metric='minkowski', n_neighbors=10, p=2, weights='distance')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53cd555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is:  95.89231094639497\n",
      "R2 is:  -0.062259811066194715\n",
      "Explained variance is: -0.06215603125256419\n"
     ]
    }
   ],
   "source": [
    "score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "637bf940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is:  105.02607930506684\n",
      "R2 is:  -0.19641985837995635\n",
      "Explained variance is: -0.19620384288202142\n"
     ]
    }
   ],
   "source": [
    "# Get the test set performance\n",
    "score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c6707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
